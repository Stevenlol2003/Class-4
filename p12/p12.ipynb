{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e2f4ace",
   "metadata": {
    "cell_type": "code",
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import otter\n",
    "# nb_name should be the name of your notebook without the .ipynb extension\n",
    "nb_name = \"p12\"\n",
    "py_filename = nb_name + \".py\"\n",
    "grader = otter.Notebook(nb_name + \".ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c73c7b",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import p12_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679ebc38",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Project 12: World University Rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e32a9fd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Learning Objectives:\n",
    "\n",
    "In this project, you will demonstrate your ability to\n",
    "\n",
    "* read and write files,\n",
    "* create and use `Pandas DataFrames`,\n",
    "* use `BeautifulSoup` to parse web pages.\n",
    "\n",
    "Please go through [Lab-P12](https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-s23-projects/-/tree/main/lab-p12) before working on this project. The lab introduces some useful techniques related to this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6834afce",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Note on Academic Misconduct:\n",
    "\n",
    "**IMPORTANT**: P12 and P13 are two parts of the same data analysis. You **cannot** switch project partners between these two projects. That is if you partner up with someone for P12, you have to sustain that partnership until the end of P13. Now may be a good time to review [our course policies](https://cs220.cs.wisc.edu/s23/syllabus.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da482a8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Testing your code:\n",
    "\n",
    "Along with this notebook, you must have downloaded the file `p12_test.py`. If you are curious about how we test your code, you can explore this file, and specifically the value of the variable `expected_json`, to understand the expected answers to the questions.\n",
    "\n",
    "For answers involving DataFrames, `p12_test.py` compares your tables to those in `p12_expected.html`, so take a moment to open that file on a web browser (from Finder/Explorer).\n",
    "\n",
    "`p12_test.py` doesn't care if you have extra rows or columns, and it doesn't care about the order of the rows or columns. However, you must have the correct values at each index/column location shown in `p12_expected.html`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6125d305",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Introduction:\n",
    "\n",
    "For this project, you're going to analyze World University Rankings!\n",
    "\n",
    "Specifically, you're going to use Pandas to analyze various statistics of the top ranked universities across the world, over the last three years.\n",
    "\n",
    "Start by downloading the files `p12_test.py`, and `p12_expected.html`.\n",
    "\n",
    "**Important Warning:** Do **not** download any of the other `json` or `html` files manually (you **must** write Python code to download these automatically, as in Lab-P12). When we run the autograder, the other files such as `rankings.json`, `2019-2020.html`, `2020-2021.html`, `2021-2022.html` will **not** be in the directory. So, unless your `p12.ipynb` downloads these files, you will get a **zero score** on the project. More details can be found in the **Setup** section of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baade2c8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Data:\n",
    "\n",
    "For this project, we will be analyzing statistics about world university rankings adapted from [here](https://cwur.org/). These are the specific webpages that we extracted the data from:\n",
    "\n",
    "* https://cwur.org/2019-20.php\n",
    "* https://cwur.org/2020-21.php\n",
    "* https://cwur.org/2021-22.php\n",
    "\n",
    "Later in the project, you will be scraping these webpages and extracting the data yourself. Since we don't want all of you bombarding these webpages with requests, we have made snapshots of these webpages, and hosted them on GitHub. You can find the snapshots here:\n",
    "\n",
    "* https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-s23-projects/-/tree/main/p12/2019-2020.html\n",
    "* https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-s23-projects/-/tree/main/p12/2020-2021.html\n",
    "* https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-s23-projects/-/tree/main/p12/2021-2022.html\n",
    "\n",
    "You will be extracting the data from these three html pages and analyzing them. However, to make the start of the project a little easier, we have already parsed the files for you! We have gathered the data from these html files, and collected them in a single json file, which can be found here:\n",
    "\n",
    "* https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-s23-projects/-/tree/main/p12/rankings.json\n",
    "\n",
    "You will work with this json file for most of this project. At the end of this project, you will generate an identical json file by parsing the html files yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c9d3a3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Project Requirements:\n",
    "\n",
    "You **may not** hardcode indices in your code. You **may not** manually download **any** files for this project, unless you are **explicitly** told to do so. For all other files, you **must** use the `download` function to download the files.\n",
    "\n",
    "**Store** your final answer for each question in the **variable specified for each question**. This step is important because Otter grades your work by comparing the value of this variable against the correct answer.\n",
    "\n",
    "For some of the questions, we'll ask you to write (then use) a function to compute the answer. If you compute the answer **without** creating the function we ask you to write, we'll **manually deduct** points from your autograder score on Gradescope, even if the way you did it produced the correct answer.\n",
    "\n",
    "Required Functions:\n",
    "- `download`\n",
    "- `parse_html`\n",
    "\n",
    "In this project, you will also be required to define certain **data structures**. If you do not create these data structures exactly as specified, we'll **manually deduct** points from your autograder score on Gradescope, even if the way you did it produced the correct answer.\n",
    "\n",
    "Required Data Structures:\n",
    "- `institutions_df`\n",
    "\n",
    "In addition, you are also **required** to follow the requirements below:\n",
    "* **Avoid using loops to iterate over pandas dataframes and instead use boolean indexing.**\n",
    "* Do **not** use `loc` to look up data in **DataFrames** or **Series**, unless you are explicitly told to do so. You are **allowed** to use `iloc`.\n",
    "* Do **not** use **absolute** paths such as `C://ms//cs220//p12`. You may **only** use **relative paths**.\n",
    "* Do **not** leave irrelevant output or test code that we didn't ask for.\n",
    "* **Avoid** calling **slow** functions multiple times within a loop.\n",
    "* Do **not** define multiple functions with the same name or define multiple versions of one function with different names. Just keep the best version.\n",
    "\n",
    "For more details on what will cause you to lose points during code review and specific requirements, please take a look at the [Grading rubric](https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-s23-projects/-/blob/main/p12/rubric.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4c9c0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Questions and Functions:\n",
    "\n",
    "Let us start by importing all the modules we will need for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c661e9b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# it is considered a good coding practice to place all import statements at the top of the notebook\n",
    "# please place all your import statements in this cell if you need to import any more modules for this project\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1f0be2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Function 1: `download(page, filename)`\n",
    "\n",
    "You **must** now copy/paste the `download` function from Lab-P12. This function **must** extract the data in the webpage `page` and store it in `filename`. If the `filename` already exists, it **must not** download the file again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c19aaaab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy/paste the 'download' function from Lab-P12\n",
    "def download(filename, url):\n",
    "    if os.path.exists(filename):\n",
    "        return str(filename) + \" already exists!\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    response.raise_for_status()\n",
    "    \n",
    "    content = response.text\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "        \n",
    "        f.close()\n",
    "        \n",
    "    return str(filename) + \" created!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6c956c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now, use `download` to pull the data from here (**do not manually download**): https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-s23-projects/-/raw/main/p12/rankings.json and store it in the file `rankings.json`. Once you have created the file, create a Dataframe `rankings` from this file.\n",
    "\n",
    "**Warning:** Make sure your `download` function meets the specifications mentioned in Lab-P12 and does **not** download the file if it already exists. The TAs will **manually deduct** points otherwise. Make sure you use the `download` function to pull the data instead of manually downloading the files. Otherwise you will get a zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f02e3c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rankings.json already exists!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the 'download' function to download the data from the webpage\n",
    "# 'https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-s23-projects/-/raw/main/p12/rankings.json'\n",
    "# to the file 'rankings.json'\n",
    "download('rankings.json', 'https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-s23-projects/-/raw/main/p12/rankings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3eb96ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# open 'rankings.json' with pd.read_json('rankings.json') and store in the variable 'rankings'\n",
    "rankings = pd.read_json('rankings.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c70715",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1:** How **many** countries do we have in our dataset?\n",
    "\n",
    "Your output **must** be an **int** representing the number of *unique* countries in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "463d3d70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'num_countries', then display it\n",
    "num_countries = len(rankings['Country'].unique())\n",
    "\n",
    "num_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e68dd9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1</pre></strong> passed! üöÄ</p>"
      ],
      "text/plain": [
       "q1 results: All test cases passed!"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec3f342",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2:** Generate a `pandas` **DataFrame** containing **all** the statistics of the **highest-ranked** institution based on `World Rank` across all the years.\n",
    "\n",
    "Your output **must** be a pandas **DataFrame** with 3 rows and 10 columns. It **must** contain all the data for the institutions with `World Rank` of *1*. It **must** look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9a4f17",
   "metadata": {},
   "source": [
    "<div><img src=\"attachment:highest_ranked.PNG\" width=\"1000\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db7302c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Rank</th>\n",
       "      <th>Year</th>\n",
       "      <th>Institution</th>\n",
       "      <th>Country</th>\n",
       "      <th>National Rank</th>\n",
       "      <th>Quality of Education Rank</th>\n",
       "      <th>Alumni Employment Rank</th>\n",
       "      <th>Quality of Faculty Rank</th>\n",
       "      <th>Research Performance Rank</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-2021</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-2022</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Rank       Year         Institution Country  National Rank  \\\n",
       "0              1  2019-2020  Harvard University     USA              1   \n",
       "2000           1  2020-2021  Harvard University     USA              1   \n",
       "4000           1  2021-2022  Harvard University     USA              1   \n",
       "\n",
       "      Quality of Education Rank  Alumni Employment Rank  \\\n",
       "0                           2.0                     1.0   \n",
       "2000                        3.0                     1.0   \n",
       "4000                        1.0                     1.0   \n",
       "\n",
       "      Quality of Faculty Rank  Research Performance Rank  Score  \n",
       "0                         1.0                        1.0  100.0  \n",
       "2000                      1.0                        1.0  100.0  \n",
       "4000                      1.0                        1.0  100.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'highest_ranked', then display it\n",
    "highest_ranked = rankings[rankings['World Rank'] == 1]\n",
    "\n",
    "highest_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce02614b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2</pre></strong> passed! üöÄ</p>"
      ],
      "text/plain": [
       "q2 results: All test cases passed!"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1192d289",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3:** Generate a `pandas` **DataFrame** containing **all** the statistics of *University of Wisconsin‚ÄìMadison*.\n",
    "\n",
    "Your output **must** be a pandas **DataFrame** with 3 rows and 10 columns. It **must** look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa03eeb",
   "metadata": {},
   "source": [
    "<div><img src=\"attachment:uw_madison.PNG\" width=\"1000\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddce6e10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Rank</th>\n",
       "      <th>Year</th>\n",
       "      <th>Institution</th>\n",
       "      <th>Country</th>\n",
       "      <th>National Rank</th>\n",
       "      <th>Quality of Education Rank</th>\n",
       "      <th>Alumni Employment Rank</th>\n",
       "      <th>Quality of Faculty Rank</th>\n",
       "      <th>Research Performance Rank</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>2019-2020</td>\n",
       "      <td>University of Wisconsin‚ÄìMadison</td>\n",
       "      <td>USA</td>\n",
       "      <td>19</td>\n",
       "      <td>28.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>87.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>26</td>\n",
       "      <td>2020-2021</td>\n",
       "      <td>University of Wisconsin‚ÄìMadison</td>\n",
       "      <td>USA</td>\n",
       "      <td>20</td>\n",
       "      <td>34.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>87.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4024</th>\n",
       "      <td>25</td>\n",
       "      <td>2021-2022</td>\n",
       "      <td>University of Wisconsin‚ÄìMadison</td>\n",
       "      <td>USA</td>\n",
       "      <td>19</td>\n",
       "      <td>33.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>87.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Rank       Year                      Institution Country  \\\n",
       "24            25  2019-2020  University of Wisconsin‚ÄìMadison     USA   \n",
       "2025          26  2020-2021  University of Wisconsin‚ÄìMadison     USA   \n",
       "4024          25  2021-2022  University of Wisconsin‚ÄìMadison     USA   \n",
       "\n",
       "      National Rank  Quality of Education Rank  Alumni Employment Rank  \\\n",
       "24               19                       28.0                    80.0   \n",
       "2025             20                       34.0                    93.0   \n",
       "4024             19                       33.0                    97.0   \n",
       "\n",
       "      Quality of Faculty Rank  Research Performance Rank  Score  \n",
       "24                       35.0                       27.0   87.3  \n",
       "2025                     34.0                       31.0   87.2  \n",
       "4024                     29.0                       32.0   87.3  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'uw_madison', then display it\n",
    "uw_madison = rankings[rankings['Institution'] == 'University of Wisconsin‚ÄìMadison']\n",
    "uw_madison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "528bea25",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3</pre></strong> passed! üåü</p>"
      ],
      "text/plain": [
       "q3 results: All test cases passed!"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009a7340",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 4:** What is the `National Rank` of the *University of Wisconsin‚ÄìMadison* in the `Year` *2021-2022*?\n",
    "\n",
    "Your output **must** be an **int**. You **must** use **Boolean indexing** on the variable `uw_madison` (from the previous question) to answer this question.\n",
    "\n",
    "**Hint:** Use Boolean indexing on the DataFrame `uw_madison` to find the data for the year `2021-2022`. You may then extract the `National Rank` column from the subset DataFrame. Finally, use `iloc` to lookup the value in the DataFrame which contains only one row and one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f0f49cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'uw_madison_nat_rank', then display it\n",
    "uw_madison_2021_2022 = uw_madison[uw_madison['Year'] == '2021-2022']\n",
    "\n",
    "uw_madison_nat_rank = uw_madison_2021_2022.iloc[0]['National Rank']\n",
    "\n",
    "uw_madison_nat_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3528a437",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "q4 results: All test cases passed!"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6556816f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 5:** What is the **average** `Score` of the *University of Wisconsin‚ÄìMadison*?\n",
    "\n",
    "Your output **must** be a **float**. You **must** use the variable `uw_madison` to answer this question.\n",
    "\n",
    "**Hint:** You **must** extract the `Score` column of the **DataFrame** `uw_madison` as a **Series**. You can find the **average** of  all the scores in a **Series** with the `Series.mean` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d06202f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.26666666666667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'uw_madison_avg_score', then display it\n",
    "uw_madison_avg_score = uw_madison['Score'].mean()\n",
    "\n",
    "uw_madison_avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d86804f1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q5</pre></strong> passed! üéâ</p>"
      ],
      "text/plain": [
       "q5 results: All test cases passed!"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3481e9b4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 6:** Generate a `pandas` **DataFrame** containing **all** the statistics of universities from the `Country` *Singapore* in the `Year` *2020-2021*.\n",
    "\n",
    "Your output **must** be a pandas **DataFrame** with 4 rows and 10 columns. It **must** look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2752bf1",
   "metadata": {},
   "source": [
    "<div><img src=\"attachment:singapore_inst.PNG\" width=\"1000\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8644a962",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Hint:** When there are **multiple** conditions to filter a **DataFrame**, you can combine all the conditions with `&` as a logical operator between them. For example, you can extract the data for all the institutions with `Quality of Education Rank <= 10` and `Quality of Faculty Rank <= 10` with:\n",
    "\n",
    "```python\n",
    "rankings[(rankings[\"Quality of Education Rank\"] <= 10) & (rankings[\"Quality of Faculty Rank\"] <= 10)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2040811d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Rank</th>\n",
       "      <th>Year</th>\n",
       "      <th>Institution</th>\n",
       "      <th>Country</th>\n",
       "      <th>National Rank</th>\n",
       "      <th>Quality of Education Rank</th>\n",
       "      <th>Alumni Employment Rank</th>\n",
       "      <th>Quality of Faculty Rank</th>\n",
       "      <th>Research Performance Rank</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>95</td>\n",
       "      <td>2020-2021</td>\n",
       "      <td>National University of Singapore</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1</td>\n",
       "      <td>330.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>140</td>\n",
       "      <td>2020-2021</td>\n",
       "      <td>Nanyang Technological University</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>996.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>80.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3150</th>\n",
       "      <td>1151</td>\n",
       "      <td>2020-2021</td>\n",
       "      <td>Singapore University of Technology and Design</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3286</th>\n",
       "      <td>1287</td>\n",
       "      <td>2020-2021</td>\n",
       "      <td>Singapore Management University</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>68.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Rank       Year                                    Institution  \\\n",
       "2094          95  2020-2021               National University of Singapore   \n",
       "2139         140  2020-2021               Nanyang Technological University   \n",
       "3150        1151  2020-2021  Singapore University of Technology and Design   \n",
       "3286        1287  2020-2021                Singapore Management University   \n",
       "\n",
       "        Country  National Rank  Quality of Education Rank  \\\n",
       "2094  Singapore              1                      330.0   \n",
       "2139  Singapore              2                        NaN   \n",
       "3150  Singapore              3                        NaN   \n",
       "3286  Singapore              4                        NaN   \n",
       "\n",
       "      Alumni Employment Rank  Quality of Faculty Rank  \\\n",
       "2094                   165.0                      NaN   \n",
       "2139                   996.0                      NaN   \n",
       "3150                     NaN                      NaN   \n",
       "3286                     NaN                      NaN   \n",
       "\n",
       "      Research Performance Rank  Score  \n",
       "2094                       41.0   82.0  \n",
       "2139                       75.0   80.3  \n",
       "3150                     1092.0   69.4  \n",
       "3286                     1225.0   68.7  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'singapore_inst', then display it\n",
    "singapore_inst = rankings[(rankings['Country'] == 'Singapore') & (rankings['Year'] == '2020-2021')]\n",
    "\n",
    "singapore_inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2baf7a67",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q6</pre></strong> passed! üöÄ</p>"
      ],
      "text/plain": [
       "q6 results: All test cases passed!"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ec1df9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 7:** In the `Year` *2019-2020*, what was the **highest-ranked** institution in the `Country` *Germany*?\n",
    "\n",
    "Your output **must** be a **string** representing the **name** of this institution.\n",
    "\n",
    "**Hint:** The highest-ranked institution in *Germany* is the institution from Germany with a `National Rank` of *1*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d715d4a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ludwig Maximilian University of Munich'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'german_best_name', then display it\n",
    "germany_2019_2020 = rankings[(rankings['Year'] == '2019-2020') & (rankings['Country'] == 'Germany')]\n",
    "germany_best = germany_2019_2020[germany_2019_2020['National Rank'] == 1]\n",
    "german_best_name_row = germany_best.iloc[0]\n",
    "german_best_name = german_best_name_row['Institution']\n",
    "\n",
    "german_best_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49099e4e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q7</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "q7 results: All test cases passed!"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712eddbc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 8:** In the `Year` *2019-2020*, list **all** the institutions in the *USA* that were ranked **better** than the highest-ranked institution in *Germany*.\n",
    "\n",
    "Your output **must** be a **list** containing the **names** of all universities from *USA* with a **better** `World Rank` than the institution `german_best_name` in the year 2019-2020. By **better** ranked, we refer to institutions with a **lower** value under the `World Rank` column.\n",
    "\n",
    "**Hint:** You could store the entire row of the highest ranked institution from Germany in a different variable in Question 7, and use it to extract its `World Rank`. You could go back to your answer for Question 7, and edit it slightly to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96e8ea1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Harvard University',\n",
       " 'Massachusetts Institute of Technology',\n",
       " 'Stanford University',\n",
       " 'Columbia University',\n",
       " 'Princeton University',\n",
       " 'University of California, Berkeley',\n",
       " 'University of Pennsylvania',\n",
       " 'University of Chicago',\n",
       " 'California Institute of Technology',\n",
       " 'Yale University',\n",
       " 'Cornell University',\n",
       " 'Northwestern University',\n",
       " 'University of California, Los Angeles',\n",
       " 'University of Michigan, Ann Arbor',\n",
       " 'Johns Hopkins University',\n",
       " 'University of Washington - Seattle',\n",
       " 'University of Illinois at Urbana‚ÄìChampaign',\n",
       " 'Duke University',\n",
       " 'University of Wisconsin‚ÄìMadison',\n",
       " 'New York University',\n",
       " 'University of California San Diego',\n",
       " 'University of Texas at Austin',\n",
       " 'University of California, San Francisco',\n",
       " 'University of North Carolina at Chapel Hill',\n",
       " 'University of Minnesota - Twin Cities',\n",
       " 'University of Texas Southwestern Medical Center',\n",
       " 'Washington University in St. Louis',\n",
       " 'University of Southern California',\n",
       " 'Brown University',\n",
       " 'Vanderbilt University',\n",
       " 'Pennsylvania State University',\n",
       " 'Rutgers University‚ÄìNew Brunswick',\n",
       " 'Dartmouth College',\n",
       " 'University of California, Davis']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'us_better_than_german_best', then display it\n",
    "us_2019_2020 = rankings[(rankings['Country'] == 'USA') & (rankings['Year'] == '2019-2020')]\n",
    "german_best_rank = german_best_name_row['World Rank']\n",
    "\n",
    "us_better_than_german = us_2019_2020[us_2019_2020['World Rank'] < german_best_rank]\n",
    "\n",
    "us_better_than_german_best = us_better_than_german['Institution'].tolist()\n",
    "\n",
    "us_better_than_german_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04d9d469",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q8</pre></strong> passed! üåü</p>"
      ],
      "text/plain": [
       "q8 results: All test cases passed!"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29035a80",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 9:** What is the **highest-ranked** institution based on `Quality of Education Rank` in *China* for the `Year` *2021-2022*?\n",
    "\n",
    "Your output **must** be a **string** representing the **name** of this institution. You may **assume** there is only one institution satisfying these requirements. By the **highest-ranked** institution, we refer to the institution with the **least** value under the `Quality of Education Rank` column.\n",
    "\n",
    "**Hint:** You can find the **minimum** value in a **Series** with the `Series.min` method. You can find the documentation [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.min.html) or by executing the line `help(pd.Series.min)` in a separate cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82380c23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fudan University'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'china_highest_qoe', then display it\n",
    "china = rankings[(rankings['Country'] == 'China') & (rankings['Year'] == '2021-2022')]\n",
    "highest_rank = china['Quality of Education Rank'].min()\n",
    "\n",
    "china_highest_qoe = china[china['Quality of Education Rank'] == highest_rank]['Institution'].iloc[0]\n",
    "\n",
    "china_highest_qoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d436f60",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q9</pre></strong> passed! üéâ</p>"
      ],
      "text/plain": [
       "q9 results: All test cases passed!"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9795ebd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 10:** What are the **top** *five* **highest-ranked** institutions based on `Research Performance Rank` in *India* for the `Year` *2020-2021*?\n",
    "\n",
    "Your output **must** be a **list** of institutions **sorted** in *increasing* order of their `Research Performance Rank`.\n",
    "\n",
    "**Hint:** For sorting a DataFrame based on the values of a particular column, you can use the `DataFrame.sort_values(by=\"column_name\")` method (where `column_name` is the column on which you want to sort). You can find the documentation [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html) or by executing the line `help(pd.Series.sort_values)` in a separate cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4dc4ed07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Indian Institute of Science',\n",
       " 'Tata Institute of Fundamental Research',\n",
       " 'Indian Institute of Technology Bombay',\n",
       " 'University of Delhi',\n",
       " 'Indian Institute of Technology Madras']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'india_highest_research', then display it\n",
    "india = rankings[(rankings['Country'] == 'India') & (rankings['Year'] == '2020-2021')]\n",
    "india_highest_research = india.sort_values(by='Research Performance Rank')['Institution'].iloc[:5].tolist()\n",
    "\n",
    "india_highest_research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "562f0cd1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q10</pre></strong> passed! üôå</p>"
      ],
      "text/plain": [
       "q10 results: All test cases passed!"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558d660",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "For the next few questions, we will be analyzing how the rankings of the institutions change across the three years in the dataset. As you might have already noticed, the list of institutions in each year's rankings are different. As a result, for several institutions in the dataset, we do not have the rankings for all three years. Since it will be more challenging to analyze such institutions, we will simply skip them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1dc123",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 11:** How **many** institutions have rankings for **all** three years?\n",
    "\n",
    "Your output **must** be an **integer**. To get started, you have been provided with a code snippet below.\n",
    "\n",
    "**Hint:** You could make **sets** of the institutions that appear in each **DataFrame**, and find their **intersection**. Look up how to find the intersection of two or more sets in Python, on the internet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75387a9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1856"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'num_institutions_2019_2020_2021', then display it\n",
    "# replace the ... with your code\n",
    "\n",
    "year_2019_ranking_df = rankings[rankings[\"Year\"] == \"2019-2020\"]\n",
    "year_2020_ranking_df = rankings[rankings[\"Year\"] == \"2020-2021\"]\n",
    "year_2021_ranking_df = rankings[rankings[\"Year\"] == \"2021-2022\"]\n",
    "\n",
    "# TODO: make sets of the institutions in each of the three years\n",
    "institutions_2019 = set(year_2019_ranking_df[\"Institution\"])\n",
    "institutions_2020 = set(year_2020_ranking_df[\"Institution\"])\n",
    "institutions_2021 = set(year_2021_ranking_df[\"Institution\"])\n",
    "# TODO: find the intersection of the three sets\n",
    "institutions_2019_2020_2021 = institutions_2019 & institutions_2020 & institutions_2021\n",
    "# TODO: find the length of the intersection\n",
    "num_institutions_2019_2020_2021 = len(institutions_2019_2020_2021)\n",
    "\n",
    "num_institutions_2019_2020_2021\n",
    "# TODO: make sets of the institutions in each of the three years\n",
    "# TODO: find the length of the intersection of the three sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f66aaf2a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q11</pre></strong> passed! üéâ</p>"
      ],
      "text/plain": [
       "q11 results: All test cases passed!"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ac67b4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Data Structure 1: `institutions_df`\n",
    "\n",
    "You are now going to create a new **DataFrame** with a **unique** list of institutions which have featured in the rankings for **all** three years, along with their `World Rank` across the three years. Specifically, the **DataFrame** would have the following four columns - `Institution`, `2019_ranking`, `2020_ranking`, and `2021_ranking`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f342c576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the variable 'institutions_df', but do NOT display it here\n",
    "\n",
    "# TODO: initalize an empty list to store the list of institutions\n",
    "# TODO: loop through the variable 'institutions_2019_2020_2021' defined above\n",
    "    # TODO: create a new dictionary with the necessary key/value pairs\n",
    "    # TODO: append the dictionary to the list\n",
    "# TODO: create the DataFrame from the list of dictionaries\n",
    "institutions_list = []\n",
    "\n",
    "for institution in institutions_2019_2020_2021:\n",
    "    row = {}\n",
    "    row['Institution'] = institution\n",
    "    row['2019_ranking'] = year_2019_ranking_df[year_2019_ranking_df['Institution'] == institution]['World Rank'].iloc[0]\n",
    "    row['2020_ranking'] = year_2020_ranking_df[year_2020_ranking_df['Institution'] == institution]['World Rank'].iloc[0]\n",
    "    row['2021_ranking'] = year_2021_ranking_df[year_2021_ranking_df['Institution'] == institution]['World Rank'].iloc[0]\n",
    "    institutions_list.append(row)\n",
    "\n",
    "institutions_df = pd.DataFrame(institutions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38ab1ea0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>institutions_df</pre></strong> passed! üôå</p>"
      ],
      "text/plain": [
       "institutions_df results: All test cases passed!"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"institutions_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a01862",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 12:** Between the years *2020-2021* and *2021-2022*, **list** the institutions which have seen an **improvement** in their `World Rank` by **more than** *200* ranks.\n",
    "\n",
    "Your output **must** be a **list** of institution names. The **order** does **not** matter. You **must** use the DataFrame `institutions_df` to answer this question.\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "1. In pandas, subtraction of two columns can be simply done using subtraction(`-`) operator. For example,\n",
    "``` python\n",
    "df[\"difference\"] = df[\"column1\"] - df[\"column2\"]\n",
    "```\n",
    "will create a *new column* `difference` with the difference of the values from the columns `column1` and `column2`.\n",
    "2. Note that an *improved* ranking means that the `World Rank` has *decreased*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23740ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['√âcole nationale sup√©rieure de chimie de Montpellier',\n",
       " 'Pomona College',\n",
       " 'USI - University of Italian Speaking Switzerland',\n",
       " 'Mohamed First University Oujda']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'improved_institutions', then display it\n",
    "improved_institutions = list(institutions_df[(institutions_df['2020_ranking'] - institutions_df['2021_ranking']) > 200]['Institution'])\n",
    "\n",
    "improved_institutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a09dd176",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q12</pre></strong> passed! üåà</p>"
      ],
      "text/plain": [
       "q12 results: All test cases passed!"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca3bd99",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 13:** Between the years *2020-2021* and *2021-2022*, which institution had the **third largest** change in its `World Rank`?\n",
    "\n",
    "Your output **must** be a **string** representing the name of the institution with the **third greatest absolute difference** between its `World Rank` in 2020-2021 and 2021-2022. You **must** use the DataFrame `institutions_df` to answer this question.\n",
    "\n",
    "<!-- **Hint:** You can find maximum value in a Series with the `Series.max` method. You can find the documentation [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.max.html). -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf539929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute and store the answer in the variable 'third_most_change_inst', then display it\n",
    "institutions_df['Rank Difference'] = abs(institutions_df['2020_ranking'] - institutions_df['2021_ranking'])\n",
    "\n",
    "# sort by the absolute difference in rank_change column and get the third institution\n",
    "third_most_change_inst = institutions_df.sort_values('Rank Difference', ascending=False).iloc[2]['Institution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33845c35",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q13</pre></strong> passed! üéâ</p>"
      ],
      "text/plain": [
       "q13 results: All test cases passed!"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c17131",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 14:** For all the three years, find the **number** of institutions that **improved** their `World Rank` between **each year** by **at least** 5 ranks.\n",
    "\n",
    "Your output **must** be an **integer** representing the number of institutions whose `World Rank` **increased** each year by **at least** 5 ranks. You **must** use the DataFrame `institutions_df` to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57acbaec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'five_improved', then display it\n",
    "diff_2019_2020 = institutions_df[\"2019_ranking\"] - institutions_df[\"2020_ranking\"]\n",
    "diff_2020_2021 = institutions_df[\"2020_ranking\"] - institutions_df[\"2021_ranking\"]\n",
    "\n",
    "five_improved = ((diff_2019_2020 >= 5) & (diff_2020_2021 >= 5)).sum()\n",
    "five_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c139e63",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q14</pre></strong> passed! üöÄ</p>"
      ],
      "text/plain": [
       "q14 results: All test cases passed!"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b38763",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 15:** In the `Year` *2020-2021*, **list** the institutions which do **not** feature in the **top** *50* in the world based on `World Ranking`, but have a `Alumni Employment Rank` **less than or equal** to *25*.\n",
    "\n",
    "Your output **must** be a **list** of institutions. The **order** does **not** matter. You **must** use the `year_2020_ranking_df` DataFrame that you created in Question 11 to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3d41704",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Keio University',\n",
       " 'INSEAD',\n",
       " \"√âcole nationale d'administration\",\n",
       " 'Waseda University',\n",
       " 'HEC Paris',\n",
       " 'International Institute for Management Development',\n",
       " 'China Europe International Business School',\n",
       " '√âcole des ponts ParisTech',\n",
       " 'Stockholm School of Economics',\n",
       " 'Indian Institute of Management Ahmedabad',\n",
       " 'Hitotsubashi University',\n",
       " 'Graduate Faculty, General Research Institute For Nonferrous Metals']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'only_top_alumni', then display it\n",
    "only_top_alumni = year_2020_ranking_df[(year_2020_ranking_df['World Rank'] > 50) & (year_2020_ranking_df['Alumni Employment Rank'] <= 25)]['Institution'].tolist()\n",
    "\n",
    "only_top_alumni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f645b278",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q15</pre></strong> passed! üôå</p>"
      ],
      "text/plain": [
       "q15 results: All test cases passed!"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bc4f07",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 16:** **List** the universities which ranked in the **top** 50 of world rankings (`World Rank`) in the `Year` *2019-2020* but **failed** to do so in the `Year` *2021-2022*.\n",
    "\n",
    "Your output **must** be a **list** of institutions. The **order** does **not** matter. You **must** use the `year_2019_ranking_df` and `year_2021_ranking_df` DataFrames that you created in Question 11 to answer this question.\n",
    "\n",
    "**Hints:**\n",
    "1. There could be institutions that are ranked in the **top** 50 in *2019-2020* but do not feature in *2021-2022*; you still want to include them in your list.\n",
    "2. You can use `sort_values` and `iloc` to identify the **top** 50 institutions.\n",
    "3. Given two *sets* `A` and `B`, you can find the elements which are in `A` but not in `B` using `A - B`. For example,\n",
    "```python\n",
    "set_A = {10, 20, 30, 40, 50}\n",
    "set_B = {20, 40, 70}\n",
    "set_A - set_B == {10, 30, 50} # elements which are in set_A but not in set_B\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a75e91c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pennsylvania State University',\n",
       " 'University of California San Diego',\n",
       " '√âcole normale sup√©rieure',\n",
       " 'University of Texas Southwestern Medical Center',\n",
       " 'Brown University',\n",
       " 'University of California, Davis',\n",
       " 'University of Southern California',\n",
       " 'Vanderbilt University',\n",
       " '√âcole Polytechnique']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'top_50_only_2019', then display it\n",
    "top_50_2019 = year_2019_ranking_df.sort_values(by='World Rank').iloc[:50]['Institution']\n",
    "top_50_2021 = year_2021_ranking_df.sort_values(by='World Rank').iloc[:50]['Institution']\n",
    "\n",
    "top_50_only_2019 = set(top_50_2019) - set(top_50_2021)\n",
    "top_50_only_2019 = list(top_50_only_2019)\n",
    "\n",
    "top_50_only_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48705c42",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q16</pre></strong> passed! üöÄ</p>"
      ],
      "text/plain": [
       "q16 results: All test cases passed!"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77b5f9b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 17:** **List** the countries which have **at least** *5* and **at most** *10* institutions featuring in the **top** *100* of world rankings (`World Rank`) in the `Year` *2020-2021*.\n",
    "\n",
    "Your output **must** be a **list**.\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "1. In a **DataFrame**, to find the **number** of times each unique value in a column repeats, you can use the `DataFrame.value_counts` method. For example,\n",
    "``` python\n",
    "rankings[\"Country\"].value_counts()\n",
    "```\n",
    "would output a `pandas` **Series** with the **indices** being the unique values of `Country` and the **values** being the **number** of times each country has featured in the `rankings` **DataFrame**. You can find the documentation [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.value_counts.html) or by using the `help` function in a separate cell. You can adapt this code to find the number of institutions from each country that features in the `Year` *2020-2021*.\n",
    "2. Just like with **DataFrames**, you can use Boolean indexing on **Series**. For example, try something like this in a separate cell below:\n",
    "```python\n",
    "a = pd.Series([100, 200, 300])\n",
    "a[a > 100]\n",
    "```\n",
    "3. You can extract the **indices** of a **Series**, `s` with `s.index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79c90c3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['United Kingdom', 'France', 'Germany']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'almost_top_countries', then display it\n",
    "top_100_2020 = year_2020_ranking_df[year_2020_ranking_df[\"World Rank\"] <= 100]\n",
    "top_100_countries = top_100_2020[\"Country\"].value_counts()\n",
    "almost_top_countries = top_100_countries[(top_100_countries >= 5) & (top_100_countries <= 10)].index.tolist()\n",
    "\n",
    "almost_top_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9578d29f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q17</pre></strong> passed! üéâ</p>"
      ],
      "text/plain": [
       "q17 results: All test cases passed!"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q17\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00719d18",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b633423",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Setup\n",
    "\n",
    "In real life, you don't often have data in nice JSON format like `rankings.json`. Instead, data needs to be *scraped* from multiple webpages and requires some cleanup before it can be used.\n",
    "\n",
    "Most of the projects in CS220 have used data obtained via web scraping, including this one. For p12, as explained above, we obtained the data by scraping the following websites:\n",
    "\n",
    "* https://cwur.org/2021-22.php\n",
    "* https://cwur.org/2020-21.php\n",
    "* https://cwur.org/2019-20.php\n",
    "\n",
    "Our `rankings.json` file was created using data from these webpages. For the rest of this project, you will write the code to **recreate** `rankings.json` file from the tables in these html pages yourself! We also do **not** want all students in this class to be making multiple requests to the webpages above, as that could be very costly for the people managing the webpages. Instead, we have made **copies** of the webpages above, which can be found here:\n",
    "\n",
    "* https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-s23-projects/-/raw/main/p12/2019-2020.html\n",
    "* https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-s23-projects/-/raw/main/p12/2020-2021.html\n",
    "* https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-s23-projects/-/raw/main/p12/2021-2022.html\n",
    "\n",
    "Before you can parse these html files, you must first *download* them. You **must** use your `download` function to download these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5564db49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-2020.html already exists!'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the 'download' function to download the data from the webpage\n",
    "# 'https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-s23-projects/-/raw/main/p12/2019-2020.html'\n",
    "# to the file '2019-2020.html'\n",
    "download('2019-2020.html', 'https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-s23-projects/-/raw/main/p12/2019-2020.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0e3ee6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-2021.html already exists!'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the 'download' function to download the data from the webpage\n",
    "# 'https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-s23-projects/-/raw/main/p12/2020-2021.html'\n",
    "# to the file '2020-2021.html'\n",
    "download('2020-2021.html', 'https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-s23-projects/-/raw/main/p12/2020-2021.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f352542",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-2022.html already exists!'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the 'download' function to download the data from the webpage\n",
    "# 'https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-s23-projects/-/raw/main/p12/2021-2022.html'\n",
    "# to the file '2021-2022.html'\n",
    "download('2021-2022.html', 'https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-s23-projects/-/raw/main/p12/2021-2022.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a474213e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 18:** Use `BeautifulSoup` to **parse** `2019-2020.html`, and find the **table** containing the ranking data. Extract the **column names** of this table and the first row of the table to create a **dictionary** where the column headers are the keys and the corresponding values are extracted from the **first** row.\n",
    "\n",
    "Your output must be a dictionary having the format as given below:\n",
    "```python\n",
    "{'World Rank': < World Rank >,\n",
    " 'Institution': < Institution Name >,\n",
    " 'Country': < Country Name >,\n",
    " 'National Rank': < National Rank >,\n",
    " 'Quality of Education Rank': < Quality of Education Rank >,\n",
    " 'Alumni Employment Rank': < Alumni Employment Rank >,\n",
    " 'Quality of Faculty Rank': < Quality of Faculty Rank >,\n",
    " 'Research Performance Rank': < Research Performance Rank >,\n",
    " 'Score': < Score >}\n",
    "```\n",
    "Where < ... > is a placeholder for the corresponding values that should be in the expected output\n",
    "<!-- Your output **must** be a **list** of **column names** from this table. There are no restrictions on 'hardcoding' **indices** or **html tags**. -->\n",
    "\n",
    "**Hint:** You **must** use the `find` or `find_all` **methods** to identify the table and its header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74d32c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'World Rank': '1',\n",
       " 'Institution': 'Harvard University',\n",
       " 'Country': 'USA',\n",
       " 'National Rank': '1',\n",
       " 'Quality of Education Rank': '2',\n",
       " 'Alumni Employment Rank': '1',\n",
       " 'Quality of Faculty Rank': '1',\n",
       " 'Research Performance Rank': '1',\n",
       " 'Score': '100'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'first_dict', then display it\n",
    "with open('2019-2020.html', encoding='utf-8') as file:\n",
    "    html_2019_2020 = file.read()\n",
    "\n",
    "bs_obj = BeautifulSoup(html_2019_2020, 'html.parser')\n",
    "\n",
    "table = bs_obj.find('table', {'class': 'table'})\n",
    "headers = [th.text.strip() for th in table.find_all('th')]\n",
    "\n",
    "row = table.find_all('tr')[1]\n",
    "values = [td.text.strip() for td in row.find_all('td')]\n",
    "\n",
    "first_dict = dict(zip(headers, values))\n",
    "    \n",
    "first_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20ed63f8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q18</pre></strong> passed! üôå</p>"
      ],
      "text/plain": [
       "q18 results: All test cases passed!"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0904827",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Function 2: `parse_html(filename)`\n",
    "\n",
    "You **must** write this function which takes in a HTML file `filename` as its input, parses it, and returns a **list** of **dictionaries** containing all the data in the **table** stored in `filename`.\n",
    "\n",
    "There are **no** restrictions on 'hardcoding' html tags.\n",
    "\n",
    "For example, the output of the function call `parse_html(\"2019-2020.html\")` **must** look like this:\n",
    "\n",
    "```python\n",
    "[{'Year': '2019-2020',\n",
    "  'World Rank': 1,\n",
    "  'Institution': 'Harvard University',\n",
    "  'Country': 'USA',\n",
    "  'National Rank': 1,\n",
    "  'Quality of Education Rank': 2,\n",
    "  'Alumni Employment Rank': 1,\n",
    "  'Quality of Faculty Rank': 1,\n",
    "  'Research Performance Rank': 1,\n",
    "  'Score': 100},\n",
    " {'Year': '2019-2020',\n",
    "  'World Rank': 2,\n",
    "  'Institution': 'Massachusetts Institute of Technology',\n",
    "  'Country': 'USA',\n",
    "  'National Rank': 2,\n",
    "  'Quality of Education Rank': 1,\n",
    "  'Alumni Employment Rank': 10,\n",
    "  'Quality of Faculty Rank': 2,\n",
    "  'Research Performance Rank': 5,\n",
    "  'Score': 96.7},\n",
    "...]\n",
    "```\n",
    "\n",
    "You can copy/paste this function from Lab-P12 if you have already defined it there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09698e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the function 'parse_html' here\n",
    "def parse_html(filename):\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        bs_obj = BeautifulSoup(f, 'html.parser')\n",
    "        \n",
    "        f.close()\n",
    "        \n",
    "    table = bs_obj.find_all('table')[0]\n",
    "    rows = table.find_all('tr')\n",
    "    data = []\n",
    "    header = [th.text.strip() for th in rows[0].find_all('th')]\n",
    "    for row in rows[1:]:\n",
    "        cols = row.find_all('td')\n",
    "        row_data = {}\n",
    "        for i, col in enumerate(cols):\n",
    "            col_text = col.text\n",
    "            if col_text == '-':\n",
    "                row_data[header[i]] = None\n",
    "            elif i == 0 or i == 3 or i == 4 or i == 5 or i == 6 or i == 7:\n",
    "                row_data[header[i]] = int(col_text)\n",
    "            elif i == len(header)-1:\n",
    "                row_data[header[i]] = float(col_text)\n",
    "            else:\n",
    "                row_data[header[i]] = col_text\n",
    "        row_data['Year'] = filename.split('.')[0]\n",
    "        data.append(row_data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385fdecc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 19:** Calculate the **average** score of the **first** 5 institutions in the file `2019-2020.html`.\n",
    "\n",
    "Your output **must** be a **float** calculated by averaging the scores from the first 5 dictionaries in the file. You **must** use the `parse_html` function to parse the file, and **slice** the list such that you would only loop through the **first five** institutions. For each **dictionary** in the **list** you must use the `Score` key to get the score for that particular institution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1743cbbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.86"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'avg_top_5', then display it\n",
    "data = parse_html(\"2019-2020.html\")\n",
    "\n",
    "scores = [d[\"Score\"] for d in data[:5]]\n",
    "\n",
    "avg_top_5 = sum(scores) / 5\n",
    "\n",
    "avg_top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a58f7671",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q19</pre></strong> passed! üåà</p>"
      ],
      "text/plain": [
       "q19 results: All test cases passed!"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q19\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826c83e1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 20:** Parse the contents of the **three** files `2019-2020.html`, `2020-2021.html`, and `2021-2022.html` and combine them to create a **single** file named `my_rankings.json`.\n",
    "\n",
    "You **must** create a **file** named `my_rankings.json` in your current directory. The contents of this file **must** be **identical** to `rankings.json`.\n",
    "\n",
    "**Hints:**\n",
    "1. Using the logic from the question above, combine the data from these three files into a single list of dicts, and write it into the file `\"my_rankings.json\"`.\n",
    "2. You can use the `write_json` function that was introduced in lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b8661730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the 'write_json' function from lecture has been provided for you here\n",
    "\n",
    "def write_json(path, data):\n",
    "    with open(path, 'w', encoding = \"utf-8\") as f:\n",
    "        json.dump(data, f, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3fe6193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parse the three files and write the contents into 'my_rankings.json'\n",
    "data = []\n",
    "for file in ['2019-2020.html', '2020-2021.html', '2021-2022.html']:\n",
    "    data += parse_html(file)\n",
    "\n",
    "write_json('my_rankings.json', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "248cce38",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q20</pre></strong> passed! üíØ</p>"
      ],
      "text/plain": [
       "q20 results: All test cases passed!"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a55922",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "Make sure you have run all cells in your notebook in order before running the following cells, so that all images/graphs appear in the output. The following cells will generate a zip file for you to submit.\n",
    "\n",
    "**SUBMISSION INSTRUCTIONS**:\n",
    "1. **Upload** the zipfile to Gradescope.\n",
    "2. Check **Gradescope otter** results as soon as the auto-grader execution gets completed. Don't worry about the score showing up as -/100.0. You only need to check that the test cases passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d9b2adf",
   "metadata": {
    "cell_type": "code",
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.save_checkpoint();",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Javascript\n",
    "display(Javascript('IPython.notebook.save_checkpoint();'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72408200",
   "metadata": {
    "cell_type": "code",
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jupytext] Reading p12.ipynb in format ipynb\n",
      "[jupytext] Writing p12.py (destination file replaced)\n"
     ]
    }
   ],
   "source": [
    "!jupytext --to py p12.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b7910d15",
   "metadata": {
    "cell_type": "code",
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running your submission against local test cases...\n",
      "\n",
      "\n",
      "\n",
      "Your submission received the following results when run against available test cases:\n",
      "\n",
      "    q1 results: All test cases passed!\n",
      "\n",
      "    q2 results: All test cases passed!\n",
      "\n",
      "    q3 results: All test cases passed!\n",
      "\n",
      "    q4 results: All test cases passed!\n",
      "\n",
      "    q5 results: All test cases passed!\n",
      "\n",
      "    q6 results: All test cases passed!\n",
      "\n",
      "    q7 results: All test cases passed!\n",
      "\n",
      "    q8 results: All test cases passed!\n",
      "\n",
      "    q9 results: All test cases passed!\n",
      "\n",
      "    q10 results: All test cases passed!\n",
      "\n",
      "    q11 results: All test cases passed!\n",
      "\n",
      "    institutions_df results: All test cases passed!\n",
      "\n",
      "    q12 results: All test cases passed!\n",
      "\n",
      "    q13 results: All test cases passed!\n",
      "\n",
      "    q14 results: All test cases passed!\n",
      "\n",
      "    q15 results: All test cases passed!\n",
      "\n",
      "    q16 results: All test cases passed!\n",
      "\n",
      "    q17 results: All test cases passed!\n",
      "\n",
      "    q18 results: All test cases passed!\n",
      "\n",
      "    q19 results: All test cases passed!\n",
      "\n",
      "    q20 results: All test cases passed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <p>Your submission has been exported. Click <a href=\"p12_2023_04_19T16_44_37_796077.zip\" download=\"p12_2023_04_19T16_44_37_796077.zip\" target=\"_blank\">here</a>\n",
       "            to download the zip file.</p>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p12_test.check_file_size(\"p12.ipynb\")\n",
    "grader.export(pdf=False, run_tests=True, files=[py_filename])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7eca6c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "institutions_df": {
     "name": "institutions_df",
     "points": 0,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"qinstitutions_df\", institutions_df.set_index('Institution').to_html())\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1": {
     "name": "q1",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q1\", num_countries)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q10": {
     "name": "q10",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q10\", india_highest_research)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q11": {
     "name": "q11",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q11\", num_institutions_2019_2020_2021)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q12": {
     "name": "q12",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q12\", improved_institutions)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q13": {
     "name": "q13",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q13\", third_most_change_inst)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q14": {
     "name": "q14",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q14\", five_improved)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q15": {
     "name": "q15",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q15\", only_top_alumni)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q16": {
     "name": "q16",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q16\", top_50_only_2019)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q17": {
     "name": "q17",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q17\", almost_top_countries)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q18": {
     "name": "q18",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q18\", first_dict)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q19": {
     "name": "q19",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q19\", avg_top_5)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q2\", highest_ranked.to_html())\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q20": {
     "name": "q20",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q20\", \"my_rankings.json\")\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q3\", uw_madison.to_html())\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q4\", uw_madison_nat_rank)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q5\", uw_madison_avg_score)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q6\", singapore_inst.to_html())\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q7\", german_best_name)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q8\", us_better_than_german_best)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9": {
     "name": "q9",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p12_test.check(\"q9\", china_highest_qoe)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
